\section{Eliminating the parsing step}
Many of the works on prettyprinting that have been published ---
such as the well-known one by Derek C. Oppen \autocite{prettyprinting} ---
propose algorithms that place line breaks into a stream of tokens.
Such a stream could be generated by a lexer;
a parser would only be required to obtain a tree structure according to
the syntactic grammar of the language.
But for any conventional formatting algorithm,
by the time it comes to actually applying the algorithm to a specific language,
parsing the tokens becomes necessary.
This is because it is sometimes hard and often impossible to
recognize coherent blocks in the token stream,
deduct the meaning of each token without knowledge about its greater surroundings or
retrieve any other information that could be used for
determining suitable spacing or line break positions when
going left to right over code written in any practical language.

An example of this problem arises with the ambigious meaning of the
\code{-} (minus) symbol \autocite[Chapter: Introduction]{prettyGoodFormattingPipeline},
which many languages use both as a
unary operator that computes the additive inverse of its operand and as a
binary operator that subtracts its right-hand operand from its left-hand operand.
Consider the following use of the `minus' symbol with its immediate neighbor tokens:
\begin{minted}{text}
  ), -, x
\end{minted}
One might intuitively proclaim that this minus symbol has to be a binary operator,
subtracting the value stored as identifier \code{x} from
whatever subexpression the parenthesis on the left closes.
But the syntactic grammars of most languages are not that simple;
the whole statement could be
\begin{minted}{c}
  if (a == b) -x;
\end{minted}
, or the language might allow parenthesized type casts and the statement looks like this:
\begin{minted}{c}
  int y = (int) -x;
\end{minted}

There are good reasons to parse the source code in order to
get better insight into its structure before attempting to prettyprint it,
but what if we still try to create a formatter that actually omits that parsing step,
printing out nicely formatted source code just based on the tokens recognized by the lexer?

\subsection{Potential benefits}
There is an obvious advantage such a formatter would have:

\paragraph{Efficiency}
In a quick test run performed by the author, the popular JavaScript parser `acorn'
took around three to five times as long to parse a large bundle of JavaScript code
than to just tokenize the same code.
Parsing can be a major bottleneck in the formatting pipeline,
so its elimination, especially when combined with a printing algorithm focused on efficiency,
could speed up the whole process of formatting significantly.

We can also expect the memory usage footprint of the formatter
to be lower in comparison to an ordinary formatter,
because we do not need to hold a large tree structure in the memory.

\paragraph{Streaming}
A non-parsing formatter could potentially be capable of writing the first line of output
right after reading the first few tokens of input and continuing to write quite consistently
as it progresses through the input code, because conceivable implementations would never
need to look at more than a section between two hard line breaking tokens at once.
Implementing such a capability would be way more trivial than it is for
formatters that parse the code first.

\paragraph{Adaptability}
A formatter that only has to understand the lexical grammar of a language,
but not its syntactic grammar, can be more easily adapted to format other languages,
even if their syntax is vastly different.

\subsection{Drawbacks}
\paragraph{Consistency}
On the other hand, it is clear that we will not be able to achieve the same degree of consistency
for some of the harder aspects of formatting
when the abstract syntax of expressions is the same,
but the concrete syntax differs.

\paragraph{Power}
We cannot trivially make significant changes --- such as removing parentheses as mentioned earlier ---
to the code, because the lack of syntactic information renders us unable to easily judge whether
\begin{itemize}
  \item such a modification would alter the semantics of the code and
  \item such a modification would actually increase the readability of the code
\end{itemize}

\paragraph{Flexibility}
Information about constructs in the code and about the greater picture is often unavailable and
we have to deal with tight limitations on what we can safely change in the code without altering semantics.
This means that we cannot always just pick a preferred formatting style that we want to produce,
but instead have to accept compromises on the output style and focus on what we \textit{can} produce.
Allowing for further user configuration options of the desired output format would be borderline inconceivable.
