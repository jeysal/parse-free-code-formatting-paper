\section{Eliminating the parsing step}
Many of the works on prettyprinting that have been published ---
such as the well-known one by Derek C. Oppen \autocite{prettyprinting} ---
propose algorithms that place line breaks into a stream of tokens.
Such a stream could be generated by a lexer;
a parser would only be required to obtain a tree structure according to
the syntactic grammar of the language.
But for any conventional formatting algorithm,
by the time it comes to actually applying the algorithm to a specific language,
parsing the tokens becomes necessary.
This is because it is sometimes hard and often impossible to
recognize coherent blocks in the token stream,
deduct the meaning of each token without knowledge about its greater surroundings or
retrieve any other information that could be used for
determining suitable spacing or line break positions when
going left to right over code written in any practical language.

An example of this problem arises with the ambigious meaning of the
\code{-} (minus) symbol \autocite[Chapter: Introduction]{prettyGoodFormattingPipeline},
which many languages use both as a
unary operator that computes the additive inverse of its operand and as a
binary operator that subtracts its right-hand operand from its left-hand operand.
Consider the following use of the `minus' symbol with its immediate neighbor tokens:
\begin{minted}{text}
  ), -, x
\end{minted}
One might intuitively proclaim that this minus symbol has to be a binary operator,
subtracting the value stored as identifier \code{x} from
whatever subexpression the parenthesis on the left closes.
But the syntactic grammars of most languages are not that simple;
the whole statement could be
\begin{minted}{c}
  if (a == b) -x;
\end{minted}
, or the language might allow parenthesized type casts and the statement looks like this:
\begin{minted}{c}
  int y = (int) -x;
\end{minted}

There are good reasons to parse the source code in order to
get better insight into its structure before attempting to prettyprint it,
but what if we still try to create a formatter that actually omits that parsing step,
printing out nicely formatted source code just based on the tokens recognized by the lexer?

\subsection{Potential benefits}
There are some obvious advantages that such a formatter would have:

\paragraph{Efficiency}
In a quick test run performed by the author, the popular JavaScript parser `acorn'
took around three to five times as long to parse a large bundle of JavaScript code
than to just tokenize the same code.
Parsing can be a major bottleneck in the formatting pipeline,
so its elimination, especially when combined with a printing algorithm focused on efficiency,
could speed up the whole process of formatting significantly.

We can also expect the memory usage footprint of the formatter
to be lower in comparison to an ordinary formatter,
because we do not need to hold a large tree structure in the memory.

\paragraph{Streaming}
A non-parsing formatter could potentially be capable of writing the first line of output
right after reading the first few tokens of input and continuing to write quite consistently
as it progresses through the input code, because conceivable implementations would never
need to look at more than a section between two hard line breaking tokens at once.
Implementing such a capability would be way more trivial than it is for
formatters that parse the code first.

\paragraph{Adaptability}
A formatter that only has to understand the lexical grammar of a language,
but not its syntactic grammar, can be more easily adapted to format other languages,
even if their syntax is vastly different.

\subsection{Drawbacks}
\paragraph{Consistency}
On the other hand, it is clear that we will not be able to achieve the same degree of consistency
for some of the harder aspects of formatting
when the abstract syntax of expressions is the same,
but the concrete syntax differs.

\paragraph{Power}
We cannot trivially make significant changes --- such as removing parentheses as mentioned earlier ---
to the code, because the lack of syntactic information renders us unable to easily judge whether
\begin{itemize}
  \item such a modification would alter the semantics of the code and
  \item such a modification would actually increase the readability of the code
\end{itemize}

\paragraph{Flexibility}
Information about constructs in the code and about the greater picture is often unavailable and
we have to deal with tight limitations on what we can safely change in the code without altering semantics.
This means that we cannot always just pick a preferred formatting style that we want to produce,
but instead have to accept compromises on the output style and focus on what we \textit{can} produce.
Allowing for further user configuration options of the desired output format would be borderline inconceivable.

\subsection{Uses}
This kind of formatter would not be suitable for some of the common use cases, including both
formatters integrated into an IDE or editor that run automatically or on key press and
formatters that provide a command-line interface (CLI) for use by developers.
Those will usually be applied to small or medium-sized source code files,
so the increased performance when compared to traditional formatters does not provide
a sufficiently large benefit to justify a trade-off in quality of the code style.

There are, however, some cases where the efficiency and potential streaming capability could
turn out to be useful for a more `on-the-fly' formatting.
Browser developer tools usually include a formatter for JavaScript files,
because those files are typically served as minified code that has
no spacing, no line breaks and consequentially no indentation at all.
Besides minification, the JavaScript preprocessing pipeline often also includes a bundling step
that merges all script and module files from the original source code into a single or very few
files in order to eliminate the need to serve each source file in a separate HTTP request.
Because of this common practice, the bundled files delivered to the browser can be quite large ---
sometimes multiple megabytes in size --- and the formatting process can take multiple seconds to complete.
Decreasing the total formatting time and the delay until the first lines are printed
could improve the developer experience in this use case,
while the `less pretty' formatting style would be tolerable,
since the code produced is usually looked at rather briefly and rarely modified.

We could also provide a CLI for the formatter and apply it to code files viewed in a terminal,
where a large delay before displaying the content would be unacceptable.
In particular, the formatter could be invoked on external code, perhaps downloaded or decompiled code.
The \code{less} pager utility supports file preprocessing by an arbitrary program
through the \code{LESSOPEN} environment variable; \autocite{lessMan}
this could be used for a formatter just as it is sometimes used for syntax highlighting
and it would greatly benefit from streaming-enabled formatting.
Some IDEs and editors can invoke an external program to process a file on keypress as well.
